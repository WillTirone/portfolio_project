---
format: 
  revealjs: 
    theme: slides.scss
    transition: fade
    slide-number: true
---

```{r setup}
library(tidyverse)
```

## modelfactory

Will Tirone

![](images\logo.png){fig-align="center"}

## Inspiration

I'm tired of writing code to do this!

```{r inspo}
#| echo: true
lm_1 = lm(mpg ~ cyl, data = mtcars)
lm_2 = lm(mpg ~ hp, data = mtcars)

bind_rows(data.frame(model = "lm_1", 
                     MSE = mean(lm_1$residuals^2),
                     RMSE = sqrt(mean(lm_1$residuals^2))),
          data.frame(model = "lm_2", 
                     MSE = mean(lm_2$residuals^2),
                     RMSE = sqrt(mean(lm_2$residuals^2)))
)
```

## Scope 

* Has anyone else done this? 
* Maybe? https://github.com/tidymodels/broom/issues/2
* *"But there are plenty of good reasons to make your own package, even if there is relevant prior work. The way experts got that way is by actually building things, often very basic things, and you deserve the same chance to learn by tinkering."* - R Packages 2e
* This is the actual R website in 2024
![](images\cran.PNG){fig-align="center"}

## Goal 

* Make a package to fix this! 
* Keep the syntax very simple, something like `cowplot`, because I can
never remember if I need `coef()`, `confint()` on summary, etc...

```{r}
#| echo: true 
#| eval: false 
library(cowplot)

cowplot::plot_grid(plot1, plot2, plot3)
```

## Package Structure 

* Much of the structure is not made by hand, but with `usethis` and `devtools` commands.
* `devtools::create_package()` creates R/, DESCRIPTION, and other files I didn't know I needed!

```
â”œâ”€â”€ R
â”‚   â”œâ”€â”€ combine.R
|   â”œâ”€â”€ helpers.R
â”œâ”€â”€ tests
â”‚   â”œâ”€â”€ testing_files.R
.
.
.
â”œâ”€â”€ DESCRIPTION
â””â”€â”€ README.md
```

## Typical Workflow

1. Edit some code in R/
2. `devtools::load_all()` and try out the code interactively 
3. Update documentation with `document()`
4. Update or add a new test, and run `test_active_file()`
5. `devtools::check()` to see if everything runs and installs smoothly
6. Commit and push changes to my GitHub repo

Sometimes in different order, but always run `check()` at many different stages to avoid bigger problems later.

## How Do We "Test" the Code We Wrote? 

![](images\install-load.png){fig-align="center"}


## modelfactory::stack_metrics() lm Example

```{r lm_metrics}
#| echo: true
library(modelfactory)

lm_1 = lm(mpg ~ cyl, data = mtcars)
lm_2 = lm(mpg ~ hp, data = mtcars)
lm_3 = lm(mpg ~ disp, data = mtcars)

modelfactory::stack_metrics(lm_1, lm_2, lm_3) |> 
  select(-adj.r.squared)
```

## modelfactory::stack_metrics() glm Example

```{r glm_metrics}
#| echo: true
glm_1 = glm(vs ~ drat + hp, data = mtcars)
glm_2 = glm(vs ~ wt + qsec, data = mtcars)
glm_3 = glm(vs ~ ., data = mtcars)

modelfactory::stack_metrics(glm_1, glm_2, glm_3)
```

## modelfactory::stack_coeff() lm Example

```{r lm_demo}
#| echo: true

modelfactory::stack_coeff(lm_1, lm_2, lm_3)
```

## Challenges 

* Dependencies: 
  - stats::confint() calls MASS::confint(), do I need to make both a dependency? 
  - lme4 and Matrix installation issues, but just used for examples in code
* I spent 90% of my time understanding how packages worked and 10% of time writing actual code
* Completely different mindset compared to solving a problem once for homework
* Writing tests is not something we do often.
 
## Challenges (cont.)

* deviance / AIC are attributes of glm, but not lmer models! 
* Similar issue with `summary()` objects and many others (add more here)
  
```{r}
cat("lm summary \n")
names(lm_1)
cat("glm summary \n")
names(glm_1)[1:20]
```

## Testing 

* Very different from our usual data science approach 
* Particularly challenging because this is visual output, not a static value
* Runs every time we run `check()` and with GitHub actions

Solution: 

```{r}
#| echo: true 
#| eval: false 
#| 
test_that("dimension of output tibble are correct", {
  expect_equal(dim(lm_metrics), c(3,6))
  expect_equal(dim(glm_metrics), c(3,4))
  expect_equal(dim(lmer_metrics), c(2,4))
})

test_that("data outputs are equal", {
  expect_snapshot_value(stack_metrics(lm_1, lm_2, lm_3), style = 'json2')
  expect_snapshot_value(stack_metrics(glm_1, glm_2, glm_3), style = 'json2')
  expect_snapshot_value(stack_metrics(lmer_1, lmer_2), style = 'json2')
})
```

## CRAN Submission Process

1. Determine the release type, which dictates the version number.
2. If the package is already on CRAN: Do due diligence on existing CRAN results. If this is a first release: confirm you are in compliance with CRAN policies.
3. Freshen up documentation files, such as README.md and NEWS.md.
4. Double check() that your package is passing cleanly on multiple operating systems and on the     released and development version of R.
5. Perform reverse dependency checks, if other packages depend on yours.
6. Submit the package to CRAN and wait for acceptance.
7. Create a GitHub release and prepare for the next version by incrementing the version number.
8. Publicize the new version.

## First Time CRAN Submission

9. usethis::use_news_md()
10. usethis::use_cran_comments()
11. Update (aspirational) install instructions in README
12. **Proofread Title: and Description:** (had to adjust based on feedback)
13. Check that all exported functions have @returns and @examples
14. Check that Authors@R: includes a copyright holder (role â€˜cphâ€™)
15. Check licensing of included files
16. Review https://github.com/DavisVaughan/extrachecks

## Good news... 

ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰  It's on CRAN! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰

```{r}
#| echo: true 
#| eval: false 
install.packages("modelfactory")
```

* Website: very easy to make a nice website quickly with `pckgdown`: https://willtirone.github.io/modelfactory/ 

* CRAN: https://cran.r-project.org/web/packages/modelfactory/index.html 

## Thank you to: 

* Dr. Colin Rundel 
* Dr. Yue Jiang 
* R Packages (2e) by Wickham and Bryan
* My friends in the MSS Program 
